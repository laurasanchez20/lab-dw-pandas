{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25d7736c-ba17-4aff-b6bb-66eba20fbf4e",
   "metadata": {},
   "source": [
    "# Lab | Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1973e9e-8be6-4039-b70e-d73ee0d94c99",
   "metadata": {},
   "source": [
    "In this lab, we will be working with the customer data from an insurance company, which can be found in the CSV file located at the following link: https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file1.csv\n",
    "\n",
    "The data includes information such as customer ID, state, gender, education, income, and other variables that can be used to perform various analyses.\n",
    "\n",
    "Throughout the lab, we will be using the pandas library in Python to manipulate and analyze the data. Pandas is a powerful library that provides various data manipulation and analysis tools, including the ability to load and manipulate data from a variety of sources, including CSV files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8045146f-f4f7-44d9-8cd9-130d6400c73a",
   "metadata": {},
   "source": [
    "### Data Description\n",
    "\n",
    "- Customer - Customer ID\n",
    "\n",
    "- ST - State where customers live\n",
    "\n",
    "- Gender - Gender of the customer\n",
    "\n",
    "- Education - Background education of customers \n",
    "\n",
    "- Customer Lifetime Value - Customer lifetime value(CLV) is the total revenue the client will derive from their entire relationship with a customer. In other words, is the predicted or calculated value of a customer over their entire duration as a policyholder with the insurance company. It is an estimation of the net profit that the insurance company expects to generate from a customer throughout their relationship with the company. Customer Lifetime Value takes into account factors such as the duration of the customer's policy, premium payments, claim history, renewal likelihood, and potential additional services or products the customer may purchase. It helps insurers assess the long-term profitability and value associated with retaining a particular customer.\n",
    "\n",
    "- Income - Customers income\n",
    "\n",
    "- Monthly Premium Auto - Amount of money the customer pays on a monthly basis as a premium for their auto insurance coverage. It represents the recurring cost that the insured person must pay to maintain their insurance policy and receive coverage for potential damages, accidents, or other covered events related to their vehicle.\n",
    "\n",
    "- Number of Open Complaints - Number of complaints the customer opened\n",
    "\n",
    "- Policy Type - There are three type of policies in car insurance (Corporate Auto, Personal Auto, and Special Auto)\n",
    "\n",
    "- Vehicle Class - Type of vehicle classes that customers have Two-Door Car, Four-Door Car SUV, Luxury SUV, Sports Car, and Luxury Car\n",
    "\n",
    "- Total Claim Amount - the sum of all claims made by the customer. It represents the total monetary value of all approved claims for incidents such as accidents, theft, vandalism, or other covered events.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a72419b-20fc-4905-817a-8c83abc59de6",
   "metadata": {},
   "source": [
    "External Resources: https://towardsdatascience.com/filtering-data-frames-in-pandas-b570b1f834b9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8ece17-e919-4e23-96c0-c7c59778436a",
   "metadata": {},
   "source": [
    "## Challenge 1: Understanding the data\n",
    "\n",
    "In this challenge, you will use pandas to explore a given dataset. Your task is to gain a deep understanding of the data by analyzing its characteristics, dimensions, and statistical properties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91437bd5-59a6-49c0-8150-ef0e6e6eb253",
   "metadata": {},
   "source": [
    "- Identify the dimensions of the dataset by determining the number of rows and columns it contains.\n",
    "- Determine the data types of each column and evaluate whether they are appropriate for the nature of the variable. You should also provide suggestions for fixing any incorrect data types.\n",
    "- Identify the number of unique values for each column and determine which columns appear to be categorical. You should also describe the unique values of each categorical column and the range of values for numerical columns, and give your insights.\n",
    "- Compute summary statistics such as mean, median, mode, standard deviation, and quartiles to understand the central tendency and distribution of the data for numerical columns. You should also provide your conclusions based on these summary statistics.\n",
    "- Compute summary statistics for categorical columns and providing your conclusions based on these statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "dd4e8cd8-a6f6-486c-a5c4-1745b0c035f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows and columns: (4008, 11)\n",
      "Customer                      object\n",
      "ST                            object\n",
      "GENDER                        object\n",
      "Education                     object\n",
      "Customer Lifetime Value       object\n",
      "Income                       float64\n",
      "Monthly Premium Auto         float64\n",
      "Number of Open Complaints     object\n",
      "Policy Type                   object\n",
      "Vehicle Class                 object\n",
      "Total Claim Amount           float64\n",
      "dtype: object\n",
      " \n",
      "Customer                     1071\n",
      "ST                              8\n",
      "GENDER                          5\n",
      "Education                       6\n",
      "Customer Lifetime Value      1027\n",
      "Income                        774\n",
      "Monthly Premium Auto          132\n",
      "Number of Open Complaints       6\n",
      "Policy Type                     3\n",
      "Vehicle Class                   6\n",
      "Total Claim Amount            761\n",
      "dtype: int64\n",
      "Value Counts for ST:\n",
      "ST\n",
      "NaN           2937\n",
      "Oregon         320\n",
      "California     211\n",
      "Arizona        186\n",
      "Cali           120\n",
      "Nevada          98\n",
      "Washington      81\n",
      "WA              30\n",
      "AZ              25\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Value Counts for GENDER:\n",
      "GENDER\n",
      "NaN       3054\n",
      "F          457\n",
      "M          413\n",
      "Male        39\n",
      "female      28\n",
      "Femal       17\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Value Counts for Education:\n",
      "Education\n",
      "NaN                     2937\n",
      "Bachelor                 324\n",
      "College                  313\n",
      "High School or Below     296\n",
      "Master                    94\n",
      "Doctor                    37\n",
      "Bachelors                  7\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Value Counts for Number of Open Complaints:\n",
      "Number of Open Complaints\n",
      "NaN       2937\n",
      "1/0/00     830\n",
      "1/1/00     138\n",
      "1/2/00      50\n",
      "1/3/00      34\n",
      "1/4/00      13\n",
      "1/5/00       6\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Value Counts for Policy Type:\n",
      "Policy Type\n",
      "NaN               2937\n",
      "Personal Auto      780\n",
      "Corporate Auto     234\n",
      "Special Auto        57\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Value Counts for Vehicle Class:\n",
      "Vehicle Class\n",
      "NaN              2937\n",
      "Four-Door Car     576\n",
      "Two-Door Car      205\n",
      "SUV               199\n",
      "Sports Car         57\n",
      "Luxury SUV         20\n",
      "Luxury Car         14\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Genero esta mal y education tambien\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file1.csv')\n",
    "\n",
    "print(f\"Rows and columns: {df.shape}\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\" \")\n",
    "unique_counts = df.nunique()\n",
    "print(unique_counts)\n",
    "\n",
    "categorical_columns = unique_counts[unique_counts < 10].index\n",
    "for column in categorical_columns:\n",
    "    print(f\"Value Counts for {column}:\")\n",
    "    print(df[column].value_counts(dropna=False))  \n",
    "    print(\"\\n\")\n",
    "print(\"Genero esta mal y education tambien\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "9d262fa4-734e-4d03-a69f-9b45dc1a26c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## Income\n",
      "Range: 0.0 to 99960.0\n",
      "Spread: 99960.0\n",
      "\n",
      "## Monthly Premium Auto\n",
      "Range: 61.0 to 35354.0\n",
      "Spread: 35293.0\n",
      "\n",
      "## Total Claim Amount\n",
      "Range: 0.382107 to 2893.239678\n",
      "Spread: 2892.857571\n",
      "Ingresos comienza en 0, es algo raro que se debe investigar\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Monthly Premium Auto</th>\n",
       "      <th>Total Claim Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1071.000000</td>\n",
       "      <td>1071.000000</td>\n",
       "      <td>1071.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>39295.701214</td>\n",
       "      <td>193.234360</td>\n",
       "      <td>404.986909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>30469.427060</td>\n",
       "      <td>1601.190369</td>\n",
       "      <td>293.027260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>0.382107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>14072.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>202.157702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>36234.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>354.729129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>64631.000000</td>\n",
       "      <td>109.500000</td>\n",
       "      <td>532.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>99960.000000</td>\n",
       "      <td>35354.000000</td>\n",
       "      <td>2893.239678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Income  Monthly Premium Auto  Total Claim Amount\n",
       "count   1071.000000           1071.000000         1071.000000\n",
       "mean   39295.701214            193.234360          404.986909\n",
       "std    30469.427060           1601.190369          293.027260\n",
       "min        0.000000             61.000000            0.382107\n",
       "25%    14072.000000             68.000000          202.157702\n",
       "50%    36234.000000             83.000000          354.729129\n",
       "75%    64631.000000            109.500000          532.800000\n",
       "max    99960.000000          35354.000000         2893.239678"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_columns = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "for col in numerical_columns:\n",
    "    min_val = df[col].min()\n",
    "    max_val = df[col].max()\n",
    "    print(f\"\\n## {col}\")\n",
    "    print(f\"Range: {min_val} to {max_val}\")\n",
    "    print(f\"Spread: {max_val - min_val}\")\n",
    "\n",
    "print(\"Ingresos comienza en 0, es algo raro que se debe investigar\")\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "38662cb1-ca8f-4e53-a49e-ab761dc2a23d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'freq' is not a valid function for 'Series' object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[269], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cat_stats \u001b[38;5;241m=\u001b[39m df[categorical_columns]\u001b[38;5;241m.\u001b[39magg([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnunique\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfreq\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(cat_stats)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRevisar Gender porque hay valores desaparecidos y no puede ser 5 los valores unicos\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:10149\u001b[0m, in \u001b[0;36mDataFrame.aggregate\u001b[1;34m(self, func, axis, *args, **kwargs)\u001b[0m\n\u001b[0;32m  10146\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n\u001b[0;32m  10148\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\u001b[38;5;28mself\u001b[39m, func\u001b[38;5;241m=\u001b[39mfunc, axis\u001b[38;5;241m=\u001b[39maxis, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m> 10149\u001b[0m result \u001b[38;5;241m=\u001b[39m op\u001b[38;5;241m.\u001b[39magg()\n\u001b[0;32m  10150\u001b[0m result \u001b[38;5;241m=\u001b[39m reconstruct_and_relabel_result(result, func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m  10151\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:928\u001b[0m, in \u001b[0;36mFrameApply.agg\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    926\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 928\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39magg()\n\u001b[0;32m    929\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;241m=\u001b[39m obj\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:193\u001b[0m, in \u001b[0;36mApply.agg\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg_dict_like()\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(func):\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;66;03m# we require a list, but not a 'str'\u001b[39;00m\n\u001b[1;32m--> 193\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg_list_like()\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(func):\n\u001b[0;32m    196\u001b[0m     f \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mget_cython_func(func)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:326\u001b[0m, in \u001b[0;36mApply.agg_list_like\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21magg_list_like\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m    319\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;124;03m    Compute aggregation in the case of a list-like argument.\u001b[39;00m\n\u001b[0;32m    321\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;124;03m    Result of aggregation.\u001b[39;00m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg_or_apply_list_like(op_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:744\u001b[0m, in \u001b[0;36mNDFrameApply.agg_or_apply_list_like\u001b[1;34m(self, op_name)\u001b[0m\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maxis\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    742\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maxis other than 0 is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 744\u001b[0m keys, results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_list_like(op_name, obj, kwargs)\n\u001b[0;32m    745\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results_list_like(keys, results)\n\u001b[0;32m    746\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:385\u001b[0m, in \u001b[0;36mApply.compute_list_like\u001b[1;34m(self, op_name, selected_obj, kwargs)\u001b[0m\n\u001b[0;32m    379\u001b[0m colg \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_gotitem(col, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, subset\u001b[38;5;241m=\u001b[39mselected_obj\u001b[38;5;241m.\u001b[39miloc[:, index])\n\u001b[0;32m    380\u001b[0m args \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    381\u001b[0m     [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs]\n\u001b[0;32m    382\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m include_axis(op_name, colg)\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\n\u001b[0;32m    384\u001b[0m )\n\u001b[1;32m--> 385\u001b[0m new_res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(colg, op_name)(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    386\u001b[0m results\u001b[38;5;241m.\u001b[39mappend(new_res)\n\u001b[0;32m    387\u001b[0m indices\u001b[38;5;241m.\u001b[39mappend(index)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4766\u001b[0m, in \u001b[0;36mSeries.aggregate\u001b[1;34m(self, func, axis, *args, **kwargs)\u001b[0m\n\u001b[0;32m   4763\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mitems())\n\u001b[0;32m   4765\u001b[0m op \u001b[38;5;241m=\u001b[39m SeriesApply(\u001b[38;5;28mself\u001b[39m, func, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m-> 4766\u001b[0m result \u001b[38;5;241m=\u001b[39m op\u001b[38;5;241m.\u001b[39magg()\n\u001b[0;32m   4767\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1430\u001b[0m, in \u001b[0;36mSeriesApply.agg\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1429\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21magg\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m-> 1430\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39magg()\n\u001b[0;32m   1431\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1432\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:193\u001b[0m, in \u001b[0;36mApply.agg\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg_dict_like()\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(func):\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;66;03m# we require a list, but not a 'str'\u001b[39;00m\n\u001b[1;32m--> 193\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg_list_like()\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(func):\n\u001b[0;32m    196\u001b[0m     f \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mget_cython_func(func)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:326\u001b[0m, in \u001b[0;36mApply.agg_list_like\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21magg_list_like\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m    319\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;124;03m    Compute aggregation in the case of a list-like argument.\u001b[39;00m\n\u001b[0;32m    321\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;124;03m    Result of aggregation.\u001b[39;00m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg_or_apply_list_like(op_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:744\u001b[0m, in \u001b[0;36mNDFrameApply.agg_or_apply_list_like\u001b[1;34m(self, op_name)\u001b[0m\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maxis\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    742\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maxis other than 0 is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 744\u001b[0m keys, results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_list_like(op_name, obj, kwargs)\n\u001b[0;32m    745\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results_list_like(keys, results)\n\u001b[0;32m    746\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:369\u001b[0m, in \u001b[0;36mApply.compute_list_like\u001b[1;34m(self, op_name, selected_obj, kwargs)\u001b[0m\n\u001b[0;32m    363\u001b[0m colg \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_gotitem(selected_obj\u001b[38;5;241m.\u001b[39mname, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, subset\u001b[38;5;241m=\u001b[39mselected_obj)\n\u001b[0;32m    364\u001b[0m args \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    365\u001b[0m     [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs]\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m include_axis(op_name, colg)\n\u001b[0;32m    367\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\n\u001b[0;32m    368\u001b[0m )\n\u001b[1;32m--> 369\u001b[0m new_res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(colg, op_name)(a, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    370\u001b[0m results\u001b[38;5;241m.\u001b[39mappend(new_res)\n\u001b[0;32m    372\u001b[0m \u001b[38;5;66;03m# make sure we find a good name\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4766\u001b[0m, in \u001b[0;36mSeries.aggregate\u001b[1;34m(self, func, axis, *args, **kwargs)\u001b[0m\n\u001b[0;32m   4763\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mitems())\n\u001b[0;32m   4765\u001b[0m op \u001b[38;5;241m=\u001b[39m SeriesApply(\u001b[38;5;28mself\u001b[39m, func, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m-> 4766\u001b[0m result \u001b[38;5;241m=\u001b[39m op\u001b[38;5;241m.\u001b[39magg()\n\u001b[0;32m   4767\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1430\u001b[0m, in \u001b[0;36mSeriesApply.agg\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1429\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21magg\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m-> 1430\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39magg()\n\u001b[0;32m   1431\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1432\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:187\u001b[0m, in \u001b[0;36mApply.agg\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    184\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_dict_like(func):\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg_dict_like()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:603\u001b[0m, in \u001b[0;36mApply.apply_str\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    601\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    602\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maxis\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis\n\u001b[1;32m--> 603\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_str(obj, func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:706\u001b[0m, in \u001b[0;36mApply._apply_str\u001b[1;34m(self, obj, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    705\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not a valid function for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 706\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(msg)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'freq' is not a valid function for 'Series' object"
     ]
    }
   ],
   "source": [
    "cat_stats = df[categorical_columns].agg(['count', 'nunique', 'freq'])\n",
    "print(cat_stats)\n",
    "print(\"Revisar Gender porque hay valores desaparecidos y no puede ser 5 los valores unicos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a703890-63db-4944-b7ab-95a4f8185120",
   "metadata": {},
   "source": [
    "## Challenge 2: analyzing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0776a403-c56a-452f-ac33-5fd4fdb06fc7",
   "metadata": {},
   "source": [
    "### Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedbc484-da4d-4f9c-9343-e1d44311a87e",
   "metadata": {},
   "source": [
    "The marketing team wants to know the top 5 less common customer locations. Create a pandas Series object that contains the customer locations and their frequencies, and then retrieve the top 5 less common locations in ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "2dca5073-4520-4f42-9390-4b92733284ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ST\n",
      "Oregon        320\n",
      "California    211\n",
      "Arizona       186\n",
      "Cali          120\n",
      "Nevada         98\n",
      "Washington     81\n",
      "WA             30\n",
      "AZ             25\n",
      "Name: count, dtype: int64\n",
      "Top 5 less common customer locations:\n",
      "ST\n",
      "AZ             25\n",
      "WA             30\n",
      "Washington     81\n",
      "Nevada         98\n",
      "Cali          120\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "location = df[\"ST\"].value_counts()\n",
    "print(location)\n",
    "location_freq_sorted = location.sort_values()\n",
    "top_5_less_common = location_freq_sorted.head()\n",
    "print(\"Top 5 less common customer locations:\")\n",
    "print(top_5_less_common)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce80f43-4afa-43c7-a78a-c917444da4e0",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "The sales team wants to know the total number of policies sold for each type of policy. Create a pandas Series object that contains the policy types and their total number of policies sold, and then retrieve the policy type with the highest number of policies sold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f13997-1555-4f98-aca6-970fda1d2c3f",
   "metadata": {},
   "source": [
    "*Hint:*\n",
    "- *Using value_counts() method simplifies this analysis.*\n",
    "- *Futhermore, there is a method that returns the index of the maximum value in a column or row.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "bcfad6c1-9af2-4b0b-9aa9-0dc5c17473c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Policy Type\n",
       "Personal Auto     780\n",
       "Corporate Auto    234\n",
       "Special Auto       57\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "Policy_Type = df[\"Policy Type\"].value_counts()\n",
    "Policy_Type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b863fd3-bf91-4d5d-86eb-be29ed9f5b70",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "The sales team wants to know if customers with Personal Auto have a lower income than those with Corporate Auto. How does the average income compare between the two policy types?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1386d75-2810-4aa1-93e0-9485aa12d552",
   "metadata": {},
   "source": [
    "- Use *loc* to create two dataframes: one containing only Personal Auto policies and one containing only Corporate Auto policies.\n",
    "- Calculate the average income for each policy.\n",
    "- Print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "0c0563cf-6f8b-463d-a321-651a972f82e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "personal_auto_df = df.loc[df['Policy Type'] == 'Personal Auto']\n",
    "corporate_auto_df = df.loc[df['Policy Type'] == 'Corporate Auto']\n",
    "personal_auto_avg_income = personal_auto_df['Income'].mean()\n",
    "corporate_auto_avg_income = corporate_auto_df['Income'].mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b16c27-f4a5-4727-a229-1f88671cf4e2",
   "metadata": {},
   "source": [
    "### Bonus: Exercise 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac584986-299b-475f-ac2e-928c16c3f512",
   "metadata": {},
   "source": [
    "Your goal is to identify customers with a high policy claim amount.\n",
    "\n",
    "Instructions:\n",
    "\n",
    "- Review again the statistics for total claim amount to gain an understanding of the data.\n",
    "- To identify potential areas for improving customer retention and profitability, we want to focus on customers with a high policy claim amount. Consider customers with a high policy claim amount to be those in the top 25% of the total claim amount. Create a pandas DataFrame object that contains information about customers with a policy claim amount greater than the 75th percentile.\n",
    "- Use DataFrame methods to calculate summary statistics about the high policy claim amount data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3af5f1-6023-4b05-9c01-d05392daa650",
   "metadata": {},
   "source": [
    "*Note: When analyzing data, we often want to focus on certain groups of values to gain insights. Percentiles are a useful tool to help us define these groups. A percentile is a measure that tells us what percentage of values in a dataset are below a certain value. For example, the 75th percentile represents the value below which 75% of the data falls. Similarly, the 25th percentile represents the value below which 25% of the data falls. When we talk about the top 25%, we are referring to the values that fall above the 75th percentile, which represent the top quarter of the data. On the other hand, when we talk about the bottom 25%, we are referring to the values that fall below the 25th percentile, which represent the bottom quarter of the data. By focusing on these groups, we can identify patterns and trends that may be useful for making decisions and taking action.*\n",
    "\n",
    "*Hint: look for a method that gives you the percentile or quantile 0.75 and 0.25 for a Pandas Series.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d234634-50bd-41e0-88f7-d5ba684455d1",
   "metadata": {},
   "source": [
    "*Hint 2: check `Boolean selection according to the values of a single column` in https://towardsdatascience.com/filtering-data-frames-in-pandas-b570b1f834b9*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b731bca6-a760-4860-a27b-a33efa712ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
